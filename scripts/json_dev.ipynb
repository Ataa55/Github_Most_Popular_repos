{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "232d89b5-6309-4e82-abb0-015c11bf6765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; } </style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c75cc68-ff63-42ec-9b4c-915622dc0a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql import functions as F\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d03982d9-fecd-494a-b184-a3969cd37f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    spark_master = \"spark://spark-service:7077\"\n",
    "    app_name = \"extratct json data\"\n",
    "    memory = \"4g\"\n",
    "    data_path = \"/home/data/archive/\"\n",
    "    \n",
    "    spark = start_spark_session(spark_master,app_name,memory)\n",
    "\n",
    "    repos_schema = T.StructType([T.StructField('id', T.LongType(), True),\n",
    "                                 T.StructField('repo_name', T.StringType(), True),\n",
    "                                 T.StructField('full_name', T.StringType(), True),\n",
    "                                 T.StructField('description', T.StringType(), True),\n",
    "                                 T.StructField('created', T.StringType(), True), \n",
    "                                 T.StructField('language', T.StringType(), True), \n",
    "                                 T.StructField('type', T.StringType(), True),\n",
    "                                 T.StructField('username', T.StringType(), True),\n",
    "                                 T.StructField('stars', T.LongType(), True),\n",
    "                                 T.StructField('forks', T.LongType(), True), \n",
    "                                 T.StructField('subscribers', T.LongType(), True),\n",
    "                                 T.StructField('open_issues', T.LongType(), True), \n",
    "                                 T.StructField('topics', T.ArrayType(T.StringType(), True), True)\n",
    "                                 ])\n",
    "    df_source_repos = spark.read.json(\"/home/data/archive/\", schema = repos_schema)\n",
    "\n",
    "    \"\"\" Create a table for programming languages called \"programming_lang\" which has two columns, \n",
    "        the programming language name and the number of repos using it.\"\"\"\n",
    "    \n",
    "    programming_lang_df = df_source_repos.groupby(\"language\")\\\n",
    "                                         .agg(F.count(\"*\").alias(\"repo_count\"))\n",
    "\n",
    "    \"\"\" Create a table for the organization-type accounts called \"organizations_stars\" which has two columns, \n",
    "        the organization name and the total number of stars across all of its repos in all the files.\"\"\"\n",
    "    \n",
    "    organizations_stars_df = df_source_repos.filter(F.col(\"type\")==\"Organization\")\\\n",
    "                                            .groupby(\"username\").agg(F.sum(\"stars\").alias(\"stars_count\"))\n",
    "\n",
    "\n",
    "    \"\"\" Create a table for the search terms called \"search_terms_relevance\" which has two columns,\n",
    "        the search term - a.k.a. the file name - and the relevance score for all the repos for this search term. \n",
    "        We use a self-defined formular for calculating the relevance \n",
    "        where relevance score = 1.5 * forks + 1.32 * subscribers + 1.04 * stars.\n",
    "    \"\"\"\n",
    "    \n",
    "    relevence_calc = 1.5 * F.col(\"forks\") + 1.32 * F.col(\"subscribers\") +  1.04 * F.col(\"stars\")\n",
    "    \n",
    "    search_terms_relevance_df = df_source_repos.withColumn(\"relevance_score\", \n",
    "                                                           F.round(relevence_calc / 100) )\\\n",
    "                                                           .select(\"repo_name\",\"relevance_score\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3fc913c-9d9d-45cb-a4e1-5aee63be8308",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "write_sdf_to_postgres_db(programming_lang_df, config.POSTGRS_CREDENTIALS,\"programming_lang\", mode = \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "542bfb88-b0be-43ec-aa63-abfee57e4240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|           repo_name|relevance_score|\n",
      "+--------------------+---------------+\n",
      "|               spark|          744.0|\n",
      "|             horovod|          162.0|\n",
      "|      SparkInternals|           84.0|\n",
      "|               delta|           61.0|\n",
      "|   TensorFlowOnSpark|           57.0|\n",
      "|              koalas|           40.0|\n",
      "|     spark-jobserver|           47.0|\n",
      "|       analytics-zoo|           38.0|\n",
      "|            ballista|           27.0|\n",
      "|               deequ|           29.0|\n",
      "|       TransmogrifAI|           29.0|\n",
      "|                vega|           25.0|\n",
      "| spark-deep-learning|           29.0|\n",
      "|spark-on-k8s-oper...|           35.0|\n",
      "|                oryx|           28.0|\n",
      "|               spark|           23.0|\n",
      "|        docker-spark|           28.0|\n",
      "|          elassandra|           21.0|\n",
      "|  spark-py-notebooks|           30.0|\n",
      "|          carbondata|           26.0|\n",
      "+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_terms_relevance_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c23168d3-8c6e-4fc9-90cb-8c8e87359edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/10 11:41:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark_master = \"spark://spark-service:7077\"\n",
    "app_name = \"extratct json data\"\n",
    "memory = \"4g\"\n",
    "data_path = \"/home/data/archive/\"\n",
    "\n",
    "spark = start_spark_session(spark_master,app_name,memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0449623a-7239-477b-b543-2d125d69ec1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "repos_schema = T.StructType([T.StructField('id', T.LongType(), True),\n",
    "                     T.StructField('repo_name', T.StringType(), True),\n",
    "                     T.StructField('full_name', T.StringType(), True),\n",
    "                     T.StructField('description', T.StringType(), True),\n",
    "                     T.StructField('created', T.StringType(), True), \n",
    "                     T.StructField('language', T.StringType(), True), \n",
    "                     T.StructField('type', T.StringType(), True),\n",
    "                     T.StructField('username', T.StringType(), True),\n",
    "                     T.StructField('stars', T.LongType(), True),\n",
    "                     T.StructField('forks', T.LongType(), True), \n",
    "                     T.StructField('subscribers', T.LongType(), True),\n",
    "                     T.StructField('open_issues', T.LongType(), True), \n",
    "                     T.StructField('topics', T.ArrayType(T.StringType(), True), True)\n",
    "                     ])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3241c3a5-f0c7-4e67-bdae-bbf72c67adce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+--------------------+-------------------+----------------+------------+-------------------+-----+-----+-----------+-----------+--------------------+\n",
      "|       id|           repo_name|           full_name|         description|            created|        language|        type|           username|stars|forks|subscribers|open_issues|              topics|\n",
      "+---------+--------------------+--------------------+--------------------+-------------------+----------------+------------+-------------------+-----+-----+-----------+-----------+--------------------+\n",
      "| 17165658|               spark|        apache/spark|Apache Spark - A ...|2014-02-25 08:00:08|           Scala|Organization|             apache|32296|25357|       2080|        242|[python, scala, r...|\n",
      "| 99846383|             horovod|     horovod/horovod|Distributed train...|2017-08-09 19:39:59|          Python|Organization|            horovod|12219| 2027|        334|        298|[tensorflow, uber...|\n",
      "| 22749672|      SparkInternals|JerryLead/SparkIn...|Notes talking abo...|2014-08-08 07:30:51|            NULL|        User|          JerryLead| 4774| 1773|        619|         27|                  []|\n",
      "|182849188|               delta|      delta-io/delta|An open-source st...|2019-04-22 18:56:51|           Scala|Organization|           delta-io| 4164|  985|        188|        180|[spark, acid, big...|\n",
      "| 79584587|   TensorFlowOnSpark|yahoo/TensorFlowO...|TensorFlowOnSpark...|2017-01-20 18:15:57|          Python|Organization|              yahoo| 3768|  966|        286|          6|[tensorflow, spar...|\n",
      "|164026325|              koalas|   databricks/koalas|Koalas: pandas AP...|2019-01-03 21:46:54|          Python|Organization|         databricks| 3095|  333|        222|        103|[spark, pandas, p...|\n",
      "| 23205911|     spark-jobserver|spark-jobserver/s...|REST job server f...|2014-08-21 23:07:47|           Scala|Organization|    spark-jobserver| 2767| 1003|        219|        106|[spark, rest-api,...|\n",
      "| 90328920|       analytics-zoo|intel-analytics/a...|Distributed Tenso...|2017-05-05 02:27:30|Jupyter Notebook|Organization|    intel-analytics| 2483|  714|        102|        560|[apache-spark, de...|\n",
      "|195277793|            ballista|ballista-compute/...|Distributed compu...|2019-07-04 17:09:41|            Rust|Organization|   ballista-compute| 2285|  148|         71|          0|[rust, arrow, dat...|\n",
      "|143925946|               deequ|       awslabs/deequ|Deequ is a librar...|2018-08-07 20:55:14|           Scala|Organization|            awslabs| 2158|  389|         70|        103|[dataquality, spa...|\n",
      "|109289451|       TransmogrifAI|salesforce/Transm...|TransmogrifAI (pr...|2017-11-02 16:15:15|           Scala|Organization|         salesforce| 2101|  374|        146|         44|[ml, automl, tran...|\n",
      "|216890889|                vega|     rajasekarv/vega|A new arguably fa...|2019-10-22 19:13:09|            Rust|        User|         rajasekarv| 2028|  179|        116|         34|                  []|\n",
      "| 92971378| spark-deep-learning|databricks/spark-...|Deep Learning Pip...|2017-05-31 17:30:28|          Python|Organization|         databricks| 1912|  494|        151|         85|                  []|\n",
      "|116165188|spark-on-k8s-oper...|GoogleCloudPlatfo...|Kubernetes operat...|2018-01-03 17:43:16|              Go|Organization|GoogleCloudPlatform| 1895|  921|         82|        327|[kubernetes, kube...|\n",
      "| 22269384|                oryx|    OryxProject/oryx|Oryx 2: Lambda ar...|2014-07-25 20:08:44|            Java|Organization|        OryxProject| 1796|  412|        214|          1|[lambda-architect...|\n",
      "|182849051|               spark|        dotnet/spark|.NET for Apache® ...|2019-04-22 18:55:55|              C#|Organization|             dotnet| 1746|  270|         82|        140|[spark, csharp, d...|\n",
      "| 43886361|        docker-spark|big-data-europe/d...|Apache Spark dock...|2015-10-08 12:19:32|           Shell|Organization|    big-data-europe| 1706|  593|         99|         38|[spark-kubernetes...|\n",
      "| 41209174|          elassandra|strapdata/elassandra|Elassandra = Elas...|2015-08-22 13:52:08|            Java|Organization|          strapdata| 1624|  204|         87|         40|[cassandra, elast...|\n",
      "| 35145949|  spark-py-notebooks|jadianes/spark-py...|Apache Spark & Py...|2015-05-06 07:45:21|Jupyter Notebook|        User|           jadianes| 1439|  893|         99|          9|[spark, python, p...|\n",
      "| 62117818|          carbondata|   apache/carbondata|High performance ...|2016-06-28 07:00:06|           Scala|Organization|             apache| 1309|  697|        129|        138|[scala, java, big...|\n",
      "+---------+--------------------+--------------------+--------------------+-------------------+----------------+------------+-------------------+-----+-----+-----------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_source_repos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7039cb3d-ce3e-4812-8109-581b7e13612c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b0ae909-2e88-41f2-a4d3-fc434d3448d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|           repo_name|relevance_score|\n",
      "+--------------------+---------------+\n",
      "|               spark|          744.0|\n",
      "|             horovod|          162.0|\n",
      "|      SparkInternals|           84.0|\n",
      "|               delta|           61.0|\n",
      "|   TensorFlowOnSpark|           57.0|\n",
      "|              koalas|           40.0|\n",
      "|     spark-jobserver|           47.0|\n",
      "|       analytics-zoo|           38.0|\n",
      "|            ballista|           27.0|\n",
      "|               deequ|           29.0|\n",
      "|       TransmogrifAI|           29.0|\n",
      "|                vega|           25.0|\n",
      "| spark-deep-learning|           29.0|\n",
      "|spark-on-k8s-oper...|           35.0|\n",
      "|                oryx|           28.0|\n",
      "|               spark|           23.0|\n",
      "|        docker-spark|           28.0|\n",
      "|          elassandra|           21.0|\n",
      "|  spark-py-notebooks|           30.0|\n",
      "|          carbondata|           26.0|\n",
      "+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_terms_relevance_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179fa605-eaa8-4a9f-9bed-225bac9fe7f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
